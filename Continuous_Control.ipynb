{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "You are welcome to use this coding environment to train your agent for the project.  Follow the instructions below to get started!\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "Run the next code cell to install a few packages.  This line will take a few minutes to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mtensorflow 1.7.1 has requirement numpy>=1.13.3, but you'll have numpy 1.12.1 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mipython 6.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.15, but you'll have prompt-toolkit 3.0.5 which is incompatible.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip -q install ./python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environments corresponding to both versions of the environment are already saved in the Workspace and can be accessed at the file paths provided below.  \n",
    "\n",
    "Please select one of the two options below for loading the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "# select this option to load version 1 (with a single agent) of the environment\n",
    "env = UnityEnvironment(file_name='/data/Reacher_One_Linux_NoVis/Reacher_One_Linux_NoVis.x86_64')\n",
    "\n",
    "# select this option to load version 2 (with 20 agents) of the environment\n",
    "# env = UnityEnvironment(file_name='/data/Reacher_Linux_NoVis/Reacher.x86_64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Note that **in this coding environment, you will not be able to watch the agents while they are training**, and you should set `train_mode=True` to restart the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info = env.reset(train_mode=True)[brain_name]      # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)# initialize the score (for each agent)\n",
    "i=0\n",
    "while True:\n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    i += 1\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        print(i)\n",
    "\n",
    "        break\n",
    "    \n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  A few **important notes**:\n",
    "- When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```\n",
    "- To structure your work, you're welcome to work directly in this Jupyter notebook, or you might like to start over with a new file!  You can see the list of files in the workspace by clicking on **_Jupyter_** in the top left corner of the notebook.\n",
    "- In this coding environment, you will not be able to watch the agents while they are training.  However, **_after training the agents_**, you can download the saved model weights to watch the agents on your own machine! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import torch\n",
    "import gym\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "class OUActionNoise:\n",
    "    def __init__(self, mu, sigma=0.075, theta=0.025, dt=1e-2, x0=None):\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        self.theta = theta\n",
    "        self.dt = dt\n",
    "        self.x0 = x0 \n",
    "        self.reset()\n",
    "        \n",
    "    def __call__(self):\n",
    "        x = self.x_prev + self.theta * (self.mu - self.x_prev) * self.dt + \\\n",
    "            self.sigma * np.sqrt(self.dt) * np.random.normal(size=self.mu.shape)\n",
    "        \n",
    "        self.x_prev = x\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    def reset(self):\n",
    "        self.x_prev = self.x0 if self.x0 is not None else np.zeros_like(self.mu) \n",
    "\n",
    "        \n",
    "class ExperienceBuffer:\n",
    "    \n",
    "    def __init__(self, batch_size, buffer_length, state_size, action_size, _reward_size=1, _isdone_size=1):\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.buffer_length = buffer_length\n",
    "        self.total_collected_samples = 0\n",
    "        self.collected_samples = 0\n",
    "        \n",
    "        self.current_states = np.array(np.zeros((buffer_length, state_size  )), dtype=np.float32)\n",
    "        self.next_states    = np.array(np.zeros((buffer_length, state_size  )), dtype=np.float32)\n",
    "        self.actions        = np.array(np.zeros((buffer_length, action_size )), dtype=np.float32)\n",
    "        self.rewards        = np.array(np.zeros((buffer_length, _reward_size)), dtype=np.float32)\n",
    "        self.isdones        = np.array(np.zeros((buffer_length, _isdone_size)), dtype=np.float32)\n",
    "        \n",
    "        self.insertion_index = 0\n",
    "        \n",
    "    def insert(self, current_state, action, reward, next_state, isdone):\n",
    "        \n",
    "        self.current_states[self.insertion_index] = current_state\n",
    "        self.next_states[self.insertion_index] = next_state\n",
    "        self.actions[self.insertion_index] = action\n",
    "        self.rewards[self.insertion_index] = reward\n",
    "        self.isdones[self.insertion_index] = float(isdone)\n",
    "        \n",
    "        self.total_collected_samples += 1\n",
    "        self.collected_samples = min(self.total_collected_samples, self.buffer_length)\n",
    "        \n",
    "        self.insertion_index = self.total_collected_samples % self.buffer_length\n",
    "            \n",
    "    def sample(self, batch_size=None):\n",
    "        batch_size = self.batch_size if batch_size is None else batch_size\n",
    "\n",
    "        indices = np.random.choice(min(self.buffer_length, self.collected_samples), batch_size)\n",
    "        \n",
    "        return {    'current_states':    self.current_states[indices],\n",
    "                    'next_states':       self.next_states[indices],\n",
    "                    'actions':           self.actions[indices],\n",
    "                    'rewards':           self.rewards[indices],\n",
    "                    'isdones':           self.isdones[indices]\n",
    "               }\n",
    "    \n",
    "class Critic(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, alpha, input_dims, fc1_dims, fc2_dims, n_actions, name, chkdir=''):\n",
    "        super().__init__()\n",
    "        self.input_dims = input_dims\n",
    "        self.fc1_dims = fc1_dims\n",
    "        self.fc2_dims = fc2_dims\n",
    "        self.n_actions = n_actions\n",
    "        self.name = name\n",
    "        self.chk_file = os.path.join(chkdir, name+'_ddpg')\n",
    "        \n",
    "        # LAYERS\n",
    "        self.fc1 = torch.nn.Linear(self.input_dims, self.fc1_dims)\n",
    "        \n",
    "        f1 = 1. / np.sqrt(self.fc1.weight.data.size()[0])\n",
    "        torch.nn.init.uniform_(self.fc1.weight.data, -f1, f1)\n",
    "        torch.nn.init.uniform_(self.fc1.bias.data, -f1, f1)\n",
    "        \n",
    "        #self.bn1 = torch.nn.LayerNorm(self.fc1_dims)\n",
    "\n",
    "        self.action_value = torch.nn.Linear(self.n_actions, self.fc1_dims)\n",
    "\n",
    "        self.fc2 = torch.nn.Linear(self.fc1_dims, self.fc2_dims)\n",
    "\n",
    "\n",
    "        f2 = 1. / np.sqrt(self.fc2.weight.data.size()[0])\n",
    "        torch.nn.init.uniform_(self.fc2.weight.data, -f2, f2)\n",
    "        torch.nn.init.uniform_(self.fc2.bias.data, -f2, f2)\n",
    "\n",
    "        #self.bn2 = torch.nn.LayerNorm(self.fc2_dims)\n",
    "\n",
    "\n",
    "        self.q = torch.nn.Linear(self.fc2_dims, 1)\n",
    "        f3 = 0.003\n",
    "        torch.nn.init.uniform_(self.q.weight.data, -f3, f3)\n",
    "        torch.nn.init.uniform_(self.q.bias.data, -f3, f3)\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=alpha)\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        self.to(self.device)\n",
    "        \n",
    "    def forward(self, state, action):\n",
    "        q_forming_state = self.fc1(state)\n",
    "        #q_forming_state = self.bn1(q_forming_state)\n",
    "\n",
    "        q_forming_action = self.action_value(action)\n",
    "\n",
    "        q_forming = torch.add(q_forming_state, q_forming_action)\n",
    "        q_forming = torch.nn.functional.relu(q_forming)\n",
    "\n",
    "        \n",
    "        q_forming = self.fc2(q_forming)\n",
    "        #q_forming_state = self.bn2(q_forming_state)\n",
    "\n",
    "        q_forming = torch.nn.functional.relu(q_forming)\n",
    "        \n",
    "        q_forming = self.q(q_forming)\n",
    "        \n",
    "        return q_forming\n",
    "        \n",
    "    def save_checkpoint(self):\n",
    "        print('saving checkpoint')\n",
    "        torch.save(self.state_dict(), self.chk_file)\n",
    "        \n",
    "    def load_checkpoint(self):\n",
    "        print('loading checkpoint')\n",
    "        torch.load_state_dict(torch.load(self.chk_file)) \n",
    "        \n",
    "class Actor(torch.nn.Module):\n",
    "    def __init__(self, alpha, input_dims, fc1_dims, fc2_dims, n_actions, name, chkdir=''):\n",
    "        super().__init__()\n",
    "        self.input_dims = input_dims\n",
    "        self.fc1_dims = fc1_dims\n",
    "        self.fc2_dims = fc2_dims\n",
    "        self.n_actions = n_actions\n",
    "        self.name = name\n",
    "        self.chk_file = os.path.join(chkdir, name+'_ddpg')\n",
    "        \n",
    "        # LAYERS\n",
    "        self.fc1 = torch.nn.Linear(self.input_dims, self.fc1_dims)\n",
    "        \n",
    "        f1 = 1. / np.sqrt(self.fc1.weight.data.size()[0])\n",
    "        torch.nn.init.uniform_(self.fc1.weight.data, -f1, f1)\n",
    "        torch.nn.init.uniform_(self.fc1.bias.data, -f1, f1)\n",
    "        \n",
    "        #self.bn1 = torch.nn.LayerNorm(self.fc1_dims)\n",
    "\n",
    "        self.fc2 = torch.nn.Linear(self.fc1_dims, self.fc2_dims)\n",
    "\n",
    "        f2 = 1. / np.sqrt(self.fc2.weight.data.size()[0])\n",
    "        torch.nn.init.uniform_(self.fc2.weight.data, -f2, f2)\n",
    "        torch.nn.init.uniform_(self.fc2.bias.data, -f2, f2)\n",
    "\n",
    "        #self.bn2 = torch.nn.LayerNorm(self.fc2_dims)\n",
    "\n",
    "        self.mu = torch.nn.Linear(self.fc2_dims, self.n_actions)\n",
    "        f3 = 0.003\n",
    "        torch.nn.init.uniform_(self.mu.weight.data, -f3, f3)\n",
    "        torch.nn.init.uniform_(self.mu.bias.data, -f3, f3)\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=alpha)\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        self.to(self.device)\n",
    "    \n",
    "    def forward(self, state):\n",
    "        actions_forming = self.fc1(state)\n",
    "        #actions_forming = self.bn1(actions_forming)\n",
    "        actions_forming = torch.nn.functional.relu(actions_forming)\n",
    "        \n",
    "        actions_forming = self.fc2(actions_forming)\n",
    "        #actions_forming = self.bn2(actions_forming)\n",
    "        actions_forming = torch.nn.functional.relu(actions_forming)\n",
    "        \n",
    "        actions_forming = self.mu(actions_forming)\n",
    "        actions_forming = torch.tanh(actions_forming)\n",
    "        \n",
    "        return actions_forming\n",
    "\n",
    "    def save_checkpoint(self):\n",
    "        print('saving checkpoint')\n",
    "        torch.save(self.state_dict(), self.chk_file)\n",
    "        \n",
    "    def load_checkpoint(self):\n",
    "        print('loading checkpoint')\n",
    "        torch.load_state_dict(torch.load(self.chk_file))     \n",
    "        \n",
    "class Agent:\n",
    "    def __init__(self, alpha_actor, alpha_critic, input_dims, tau, env, gamma=0.999, n_actions=2, max_size=100000,\n",
    "                layer1_size=400, layer2_size=300, batch_size=64):\n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "        self.memory = ExperienceBuffer(batch_size=batch_size, buffer_length=max_size, state_size=input_dims, action_size=n_actions)\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.actor = Actor(alpha_actor, input_dims, layer1_size, layer2_size, n_actions=n_actions, name='Actor')\n",
    "        self.actor_target = Actor(alpha_actor, input_dims, layer1_size, layer2_size, n_actions=n_actions, name='ActorTarget')\n",
    "        \n",
    "        self.critic = Critic(alpha_critic, input_dims, layer1_size, layer2_size, n_actions=n_actions, name='Critic')\n",
    "        self.critic_target = Critic(alpha_critic, input_dims, layer1_size, layer2_size, n_actions=n_actions, name='CriticTarget')\n",
    "        \n",
    "        self.noise = OUActionNoise(mu=np.zeros(n_actions))\n",
    "        print('initial noise', self.noise())\n",
    "        \n",
    "        self.project_parameters_to_targets(tau=1.)\n",
    "        \n",
    "    def choose_action(self, state):\n",
    "        self.actor.eval()\n",
    "        state = torch.tensor(state, dtype=torch.float).to(self.actor.device)\n",
    "        with torch.no_grad():\n",
    "            mu = self.actor(state).to(self.actor.device)\n",
    "        mu_prime = mu + torch.tensor(self.noise(), dtype=torch.float).to(self.actor.device)\n",
    "        \n",
    "        self.actor.train()\n",
    "        return np.clip(mu_prime.cpu().detach().numpy(), -1, 1)\n",
    "    \n",
    "    def remark(self, current_state, action, reward, next_state, isdone): #teljesen felesleges wrapper\n",
    "        self.memory.insert(current_state, action, reward, next_state,  isdone)\n",
    "\n",
    "    def learn(self):\n",
    "        if self.memory.collected_samples >= self.batch_size:\n",
    "            sampled_data_ = self.memory.sample(self.batch_size)\n",
    "            \n",
    "            state0_        = torch.tensor(sampled_data_['current_states'], dtype=torch.float).to(self.critic.device)\n",
    "            actionset0_    = torch.tensor(sampled_data_['actions'],        dtype=torch.float).to(self.critic.device)\n",
    "            reward1_       = torch.tensor(sampled_data_['rewards'],        dtype=torch.float).to(self.critic.device)\n",
    "            state1_        = torch.tensor(sampled_data_['next_states'],    dtype=torch.float).to(self.critic.device)\n",
    "            isdone_        = torch.tensor(sampled_data_['isdones'],        dtype=torch.float).to(self.critic.device)\n",
    "            \n",
    "            #self.actor.eval()            \n",
    "            #self.actor_target.eval()\n",
    "            #self.critic_target.eval()\n",
    "            #self.critic.eval()\n",
    "            \n",
    "            actionset1_t_   = self.actor_target(state1_) # t1 [evaled] actionset @ actor target\n",
    "            q1_t_           = self.critic_target(state1_, actionset1_t_) # t1 [evaled] Q-value @ critic target \n",
    "            \n",
    "            q0_             = self.critic(state0_, actionset0_) # t0 [evaled] Q-value @ critic local\n",
    "            \n",
    "            with torch.no_grad(): \n",
    "                q0_calc_    = reward1_ + self.gamma * q1_t_ * (1. - isdone_) # t0 [calculated] Q-value @ code\n",
    "                        \n",
    "            self.critic.train()\n",
    "            \n",
    "            critic_loss = torch.nn.functional.mse_loss(q0_, q0_calc_) # loss function: critic@local <- f(actor@target, critic@target)\n",
    "            \n",
    "            self.critic.optimizer.zero_grad()\n",
    "            critic_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.critic.parameters(), 1)\n",
    "            self.critic.optimizer.step()\n",
    "            \n",
    "            self.critic.eval()\n",
    "            \n",
    "            actionset0X_ = self.actor(state0_) # t0 [evaled] actionset @ actor local \n",
    "            \n",
    "            self.actor.train() \n",
    "            \n",
    "            actor_loss = -self.critic(state0_, actionset0X_).mean() # loss function: actor@local <- critic@local\n",
    "            \n",
    "            self.actor.optimizer.zero_grad()\n",
    "            actor_loss.backward()\n",
    "            self.actor.optimizer.step()\n",
    "            \n",
    "            self.project_parameters_to_targets()\n",
    "            \n",
    "    def project_parameters_to_targets(self, tau=None):\n",
    "            tau = self.tau if tau is None else tau\n",
    "                        \n",
    "            for local, target in [(self.actor, self.actor_target), (self.critic, self.critic_target)]:\n",
    "                for local_param, target_param in zip(local.parameters(), target.parameters()):\n",
    "                    target_param.data.copy_(tau * (local_param.data) + (1. - tau) * target_param.data)  \n",
    "                    \n",
    "    def save_models(self):\n",
    "        for network in [self.actor, self.actor_target, self.critic, self.critic_target]:\n",
    "            network.save_checkpoint()\n",
    "        \n",
    "    def load_models(self):\n",
    "        for network in [self.actor, self.actor_target, self.critic, self.critic_target]:\n",
    "            network.load_checkpoint()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_episode_scores(scores, target):\n",
    "    plt.plot(scores, color='blue')\n",
    "    plt.plot(np.hstack([np.empty((100,)) * np.nan, np.convolve(scores, np.ones((100,))/100, mode='valid')[:]]), color='orange')\n",
    "    plt.plot(np.ones((len(scores),)) * float(target), color='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial noise [-0.00157716 -0.00920142 -0.0082899   0.00578199]\n"
     ]
    }
   ],
   "source": [
    "agent = Agent(alpha_actor=0.000075, alpha_critic=0.0005, input_dims=33, tau=0.001, env=env, \n",
    "              batch_size=128, layer1_size=512, layer2_size=256, n_actions=4, gamma=.9)\n",
    "\n",
    "score_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... AvgLast100Score: 0.00000...\n",
      "Epoch: 2... AvgLast100Score: 0.17000...\n",
      "Epoch: 3... AvgLast100Score: 0.17667...\n",
      "Epoch: 4... AvgLast100Score: 0.47000...\n",
      "Epoch: 5... AvgLast100Score: 0.57400...\n",
      "Epoch: 6... AvgLast100Score: 0.61667...\n",
      "Epoch: 7... AvgLast100Score: 0.63429...\n",
      "Epoch: 8... AvgLast100Score: 0.58625...\n",
      "Epoch: 9... AvgLast100Score: 0.54889...\n",
      "Epoch: 10... AvgLast100Score: 0.53900...\n",
      "Epoch: 11... AvgLast100Score: 0.54091...\n",
      "Epoch: 12... AvgLast100Score: 0.52500...\n",
      "Epoch: 13... AvgLast100Score: 0.50615...\n",
      "Epoch: 14... AvgLast100Score: 0.53214...\n",
      "Epoch: 15... AvgLast100Score: 0.56267...\n",
      "Epoch: 16... AvgLast100Score: 0.57125...\n",
      "Epoch: 17... AvgLast100Score: 0.55471...\n",
      "Epoch: 18... AvgLast100Score: 0.55889...\n",
      "Epoch: 19... AvgLast100Score: 0.52947...\n",
      "Epoch: 20... AvgLast100Score: 0.55750...\n",
      "Epoch: 21... AvgLast100Score: 0.55238...\n",
      "Epoch: 22... AvgLast100Score: 0.54318...\n",
      "Epoch: 23... AvgLast100Score: 0.56174...\n",
      "Epoch: 24... AvgLast100Score: 0.58292...\n",
      "Epoch: 25... AvgLast100Score: 0.60840...\n",
      "Epoch: 26... AvgLast100Score: 0.64269...\n",
      "Epoch: 27... AvgLast100Score: 0.65222...\n",
      "Epoch: 28... AvgLast100Score: 0.66321...\n",
      "Epoch: 29... AvgLast100Score: 0.69931...\n",
      "Epoch: 30... AvgLast100Score: 0.71200...\n",
      "Epoch: 31... AvgLast100Score: 0.71677...\n",
      "Epoch: 32... AvgLast100Score: 0.70875...\n",
      "Epoch: 33... AvgLast100Score: 0.70091...\n",
      "Epoch: 34... AvgLast100Score: 0.71647...\n",
      "Epoch: 35... AvgLast100Score: 0.70629...\n",
      "Epoch: 36... AvgLast100Score: 0.69750...\n",
      "Epoch: 37... AvgLast100Score: 0.72054...\n",
      "Epoch: 38... AvgLast100Score: 0.71684...\n",
      "Epoch: 39... AvgLast100Score: 0.73026...\n",
      "Epoch: 40... AvgLast100Score: 0.76875...\n",
      "Epoch: 41... AvgLast100Score: 0.78927...\n",
      "Epoch: 42... AvgLast100Score: 0.81381...\n",
      "Epoch: 43... AvgLast100Score: 0.83930...\n",
      "Epoch: 44... AvgLast100Score: 0.86591...\n",
      "Epoch: 45... AvgLast100Score: 0.88311...\n",
      "Epoch: 46... AvgLast100Score: 0.90283...\n",
      "Epoch: 47... AvgLast100Score: 0.90787...\n",
      "Epoch: 48... AvgLast100Score: 0.91458...\n",
      "Epoch: 49... AvgLast100Score: 0.94755...\n",
      "Epoch: 50... AvgLast100Score: 0.97140...\n",
      "Epoch: 51... AvgLast100Score: 0.99980...\n",
      "Epoch: 52... AvgLast100Score: 1.03250...\n",
      "Epoch: 53... AvgLast100Score: 1.05811...\n",
      "Epoch: 54... AvgLast100Score: 1.07889...\n",
      "Epoch: 55... AvgLast100Score: 1.08000...\n",
      "Epoch: 56... AvgLast100Score: 1.10411...\n",
      "Epoch: 57... AvgLast100Score: 1.14719...\n",
      "Epoch: 58... AvgLast100Score: 1.16431...\n",
      "Epoch: 59... AvgLast100Score: 1.17034...\n",
      "Epoch: 60... AvgLast100Score: 1.18700...\n",
      "Epoch: 61... AvgLast100Score: 1.21033...\n",
      "Epoch: 62... AvgLast100Score: 1.21274...\n",
      "Epoch: 63... AvgLast100Score: 1.23317...\n",
      "Epoch: 64... AvgLast100Score: 1.22797...\n",
      "Epoch: 65... AvgLast100Score: 1.24631...\n",
      "Epoch: 66... AvgLast100Score: 1.27212...\n",
      "Epoch: 67... AvgLast100Score: 1.28045...\n",
      "Epoch: 68... AvgLast100Score: 1.29662...\n",
      "Epoch: 69... AvgLast100Score: 1.32246...\n",
      "Epoch: 70... AvgLast100Score: 1.31914...\n",
      "Epoch: 71... AvgLast100Score: 1.35789...\n",
      "Epoch: 72... AvgLast100Score: 1.36500...\n",
      "Epoch: 73... AvgLast100Score: 1.36397...\n",
      "Epoch: 74... AvgLast100Score: 1.35311...\n",
      "Epoch: 75... AvgLast100Score: 1.35880...\n",
      "Epoch: 76... AvgLast100Score: 1.39526...\n",
      "Epoch: 77... AvgLast100Score: 1.40623...\n",
      "Epoch: 78... AvgLast100Score: 1.41628...\n",
      "Epoch: 79... AvgLast100Score: 1.43519...\n",
      "Epoch: 80... AvgLast100Score: 1.45112...\n",
      "Epoch: 81... AvgLast100Score: 1.46333...\n",
      "Epoch: 82... AvgLast100Score: 1.48720...\n",
      "Epoch: 83... AvgLast100Score: 1.49687...\n",
      "Epoch: 84... AvgLast100Score: 1.52881...\n",
      "Epoch: 85... AvgLast100Score: 1.56482...\n",
      "Epoch: 86... AvgLast100Score: 1.57977...\n",
      "Epoch: 87... AvgLast100Score: 1.60632...\n",
      "Epoch: 88... AvgLast100Score: 1.61284...\n",
      "Epoch: 89... AvgLast100Score: 1.63865...\n",
      "Epoch: 90... AvgLast100Score: 1.66600...\n",
      "Epoch: 91... AvgLast100Score: 1.68187...\n",
      "Epoch: 92... AvgLast100Score: 1.70130...\n",
      "Epoch: 93... AvgLast100Score: 1.73129...\n",
      "Epoch: 94... AvgLast100Score: 1.72957...\n",
      "Epoch: 95... AvgLast100Score: 1.73937...\n",
      "Epoch: 96... AvgLast100Score: 1.77448...\n",
      "Epoch: 97... AvgLast100Score: 1.77670...\n",
      "Epoch: 98... AvgLast100Score: 1.78143...\n",
      "Epoch: 99... AvgLast100Score: 1.79030...\n",
      "Epoch: 100... AvgLast100Score: 1.81200...\n",
      "Epoch: 101... AvgLast100Score: 1.83670...\n",
      "Epoch: 102... AvgLast100Score: 1.86390...\n",
      "Epoch: 103... AvgLast100Score: 1.89800...\n",
      "Epoch: 104... AvgLast100Score: 1.91310...\n",
      "Epoch: 105... AvgLast100Score: 1.92570...\n",
      "Epoch: 106... AvgLast100Score: 1.93800...\n",
      "Epoch: 107... AvgLast100Score: 1.95830...\n",
      "Epoch: 108... AvgLast100Score: 1.99890...\n",
      "Epoch: 109... AvgLast100Score: 2.01740...\n",
      "Epoch: 110... AvgLast100Score: 2.04330...\n",
      "Epoch: 111... AvgLast100Score: 2.06430...\n",
      "Epoch: 112... AvgLast100Score: 2.11260...\n",
      "Epoch: 113... AvgLast100Score: 2.15100...\n",
      "Epoch: 114... AvgLast100Score: 2.19240...\n",
      "Epoch: 115... AvgLast100Score: 2.22390...\n",
      "Epoch: 116... AvgLast100Score: 2.23910...\n",
      "Epoch: 117... AvgLast100Score: 2.28780...\n",
      "Epoch: 118... AvgLast100Score: 2.34050...\n",
      "Epoch: 119... AvgLast100Score: 2.37830...\n",
      "Epoch: 120... AvgLast100Score: 2.40350...\n",
      "Epoch: 121... AvgLast100Score: 2.43420...\n",
      "Epoch: 122... AvgLast100Score: 2.48160...\n",
      "Epoch: 123... AvgLast100Score: 2.51440...\n",
      "Epoch: 124... AvgLast100Score: 2.52860...\n",
      "Epoch: 125... AvgLast100Score: 2.58690...\n",
      "Epoch: 126... AvgLast100Score: 2.61760...\n",
      "Epoch: 127... AvgLast100Score: 2.68680...\n",
      "Epoch: 128... AvgLast100Score: 2.73770...\n",
      "Epoch: 129... AvgLast100Score: 2.86600...\n",
      "Epoch: 130... AvgLast100Score: 2.95280...\n",
      "Epoch: 131... AvgLast100Score: 3.03630...\n",
      "Epoch: 132... AvgLast100Score: 3.08740...\n",
      "Epoch: 133... AvgLast100Score: 3.14100...\n",
      "Epoch: 134... AvgLast100Score: 3.19490...\n",
      "Epoch: 135... AvgLast100Score: 3.23440...\n",
      "Epoch: 136... AvgLast100Score: 3.28140...\n",
      "Epoch: 137... AvgLast100Score: 3.32830...\n",
      "Epoch: 138... AvgLast100Score: 3.37580...\n",
      "Epoch: 139... AvgLast100Score: 3.39360...\n",
      "Epoch: 140... AvgLast100Score: 3.43050...\n",
      "Epoch: 141... AvgLast100Score: 3.45660...\n",
      "Epoch: 142... AvgLast100Score: 3.50390...\n",
      "Epoch: 143... AvgLast100Score: 3.51360...\n",
      "Epoch: 144... AvgLast100Score: 3.58080...\n",
      "Epoch: 145... AvgLast100Score: 3.64150...\n",
      "Epoch: 146... AvgLast100Score: 3.71710...\n",
      "Epoch: 147... AvgLast100Score: 3.75520...\n",
      "Epoch: 148... AvgLast100Score: 3.80710...\n",
      "Epoch: 149... AvgLast100Score: 3.80680...\n",
      "Epoch: 150... AvgLast100Score: 3.86850...\n",
      "Epoch: 151... AvgLast100Score: 3.89950...\n",
      "Epoch: 152... AvgLast100Score: 3.94740...\n",
      "Epoch: 153... AvgLast100Score: 3.98700...\n",
      "Epoch: 154... AvgLast100Score: 3.99710...\n",
      "Epoch: 155... AvgLast100Score: 4.05110...\n",
      "Epoch: 156... AvgLast100Score: 4.08990...\n",
      "Epoch: 157... AvgLast100Score: 4.11900...\n",
      "Epoch: 158... AvgLast100Score: 4.17040...\n",
      "Epoch: 159... AvgLast100Score: 4.19390...\n",
      "Epoch: 160... AvgLast100Score: 4.22830...\n",
      "Epoch: 161... AvgLast100Score: 4.29870...\n",
      "Epoch: 162... AvgLast100Score: 4.34970...\n",
      "Epoch: 163... AvgLast100Score: 4.40420...\n",
      "Epoch: 164... AvgLast100Score: 4.45900...\n",
      "Epoch: 165... AvgLast100Score: 4.52530...\n",
      "Epoch: 166... AvgLast100Score: 4.56010...\n",
      "Epoch: 167... AvgLast100Score: 4.62280...\n",
      "Epoch: 168... AvgLast100Score: 4.64350...\n",
      "Epoch: 169... AvgLast100Score: 4.69840...\n",
      "Epoch: 170... AvgLast100Score: 4.73810...\n",
      "Epoch: 171... AvgLast100Score: 4.74070...\n",
      "Epoch: 172... AvgLast100Score: 4.77040...\n",
      "Epoch: 173... AvgLast100Score: 4.82910...\n",
      "Epoch: 174... AvgLast100Score: 4.86550...\n",
      "Epoch: 175... AvgLast100Score: 4.94360...\n",
      "Epoch: 176... AvgLast100Score: 4.97440...\n",
      "Epoch: 177... AvgLast100Score: 5.00140...\n",
      "Epoch: 178... AvgLast100Score: 5.02640...\n",
      "Epoch: 179... AvgLast100Score: 5.03350...\n",
      "Epoch: 180... AvgLast100Score: 5.02310...\n",
      "Epoch: 181... AvgLast100Score: 5.06570...\n",
      "Epoch: 182... AvgLast100Score: 5.08940...\n",
      "Epoch: 183... AvgLast100Score: 5.13470...\n",
      "Epoch: 184... AvgLast100Score: 5.18430...\n",
      "Epoch: 185... AvgLast100Score: 5.19590...\n",
      "Epoch: 186... AvgLast100Score: 5.25030...\n",
      "Epoch: 187... AvgLast100Score: 5.30070...\n",
      "Epoch: 188... AvgLast100Score: 5.34810...\n",
      "Epoch: 189... AvgLast100Score: 5.37060...\n",
      "Epoch: 190... AvgLast100Score: 5.41740...\n",
      "Epoch: 191... AvgLast100Score: 5.50130...\n",
      "Epoch: 192... AvgLast100Score: 5.56810...\n",
      "Epoch: 193... AvgLast100Score: 5.61960...\n",
      "Epoch: 194... AvgLast100Score: 5.69880...\n",
      "Epoch: 195... AvgLast100Score: 5.74650...\n",
      "Epoch: 196... AvgLast100Score: 5.79970...\n",
      "Epoch: 197... AvgLast100Score: 5.84230...\n",
      "Epoch: 198... AvgLast100Score: 5.92900...\n",
      "Epoch: 199... AvgLast100Score: 6.00950...\n",
      "Epoch: 200... AvgLast100Score: 6.06900...\n",
      "Epoch: 201... AvgLast100Score: 6.13550...\n",
      "Epoch: 202... AvgLast100Score: 6.18190...\n",
      "Epoch: 203... AvgLast100Score: 6.22080...\n",
      "Epoch: 204... AvgLast100Score: 6.27380...\n",
      "Epoch: 205... AvgLast100Score: 6.33840...\n",
      "Epoch: 206... AvgLast100Score: 6.51640...\n",
      "Epoch: 207... AvgLast100Score: 6.55960...\n",
      "Epoch: 208... AvgLast100Score: 6.56260...\n",
      "Epoch: 209... AvgLast100Score: 6.60880...\n",
      "Epoch: 210... AvgLast100Score: 6.71920...\n",
      "Epoch: 211... AvgLast100Score: 6.78010...\n",
      "Epoch: 212... AvgLast100Score: 6.83630...\n",
      "Epoch: 213... AvgLast100Score: 6.88840...\n",
      "Epoch: 214... AvgLast100Score: 6.95450...\n",
      "Epoch: 215... AvgLast100Score: 6.97920...\n",
      "Epoch: 216... AvgLast100Score: 7.03530...\n",
      "Epoch: 217... AvgLast100Score: 7.13090...\n",
      "Epoch: 218... AvgLast100Score: 7.22620...\n",
      "Epoch: 219... AvgLast100Score: 7.39480...\n",
      "Epoch: 220... AvgLast100Score: 7.44310...\n",
      "Epoch: 221... AvgLast100Score: 7.53210...\n",
      "Epoch: 222... AvgLast100Score: 7.76810...\n",
      "Epoch: 223... AvgLast100Score: 7.79500...\n",
      "Epoch: 224... AvgLast100Score: 7.83590...\n",
      "Epoch: 225... AvgLast100Score: 7.86770...\n",
      "Epoch: 226... AvgLast100Score: 7.94800...\n",
      "Epoch: 227... AvgLast100Score: 7.97350...\n",
      "Epoch: 228... AvgLast100Score: 8.03530...\n",
      "Epoch: 229... AvgLast100Score: 8.07080...\n",
      "Epoch: 230... AvgLast100Score: 8.07220...\n",
      "Epoch: 231... AvgLast100Score: 8.13210...\n",
      "Epoch: 232... AvgLast100Score: 8.19240...\n",
      "Epoch: 233... AvgLast100Score: 8.21660...\n",
      "Epoch: 234... AvgLast100Score: 8.25890...\n",
      "Epoch: 235... AvgLast100Score: 8.32700...\n",
      "Epoch: 236... AvgLast100Score: 8.42560...\n",
      "Epoch: 237... AvgLast100Score: 8.46470...\n",
      "Epoch: 238... AvgLast100Score: 8.51760...\n",
      "Epoch: 239... AvgLast100Score: 8.59450...\n",
      "Epoch: 240... AvgLast100Score: 8.72930...\n",
      "Epoch: 241... AvgLast100Score: 8.80190...\n",
      "Epoch: 242... AvgLast100Score: 8.88490...\n",
      "Epoch: 243... AvgLast100Score: 9.00660...\n",
      "Epoch: 244... AvgLast100Score: 9.05260...\n",
      "Epoch: 245... AvgLast100Score: 9.08940...\n",
      "Epoch: 246... AvgLast100Score: 9.06960...\n",
      "Epoch: 247... AvgLast100Score: 9.12230...\n",
      "Epoch: 248... AvgLast100Score: 9.20130...\n",
      "Epoch: 249... AvgLast100Score: 9.30800...\n",
      "Epoch: 250... AvgLast100Score: 9.32880...\n",
      "Epoch: 251... AvgLast100Score: 9.35920...\n",
      "Epoch: 252... AvgLast100Score: 9.41720...\n",
      "Epoch: 253... AvgLast100Score: 9.49560...\n",
      "Epoch: 254... AvgLast100Score: 9.61100...\n",
      "Epoch: 255... AvgLast100Score: 9.63030...\n",
      "Epoch: 256... AvgLast100Score: 9.66890...\n",
      "Epoch: 257... AvgLast100Score: 9.72050...\n",
      "Epoch: 258... AvgLast100Score: 9.75220...\n",
      "Epoch: 259... AvgLast100Score: 9.84220...\n",
      "Epoch: 260... AvgLast100Score: 9.84030...\n",
      "Epoch: 261... AvgLast100Score: 9.81400...\n",
      "Epoch: 262... AvgLast100Score: 9.81780...\n",
      "Epoch: 263... AvgLast100Score: 9.84170...\n",
      "Epoch: 264... AvgLast100Score: 9.90910...\n",
      "Epoch: 265... AvgLast100Score: 9.89790...\n",
      "Epoch: 266... AvgLast100Score: 9.97620...\n",
      "Epoch: 267... AvgLast100Score: 10.05320...\n",
      "Epoch: 268... AvgLast100Score: 10.20450...\n",
      "Epoch: 269... AvgLast100Score: 10.27170...\n",
      "Epoch: 270... AvgLast100Score: 10.37430...\n",
      "Epoch: 271... AvgLast100Score: 10.43880...\n",
      "Epoch: 272... AvgLast100Score: 10.52850...\n",
      "Epoch: 273... AvgLast100Score: 10.59890...\n",
      "Epoch: 274... AvgLast100Score: 10.78060...\n",
      "Epoch: 275... AvgLast100Score: 10.78960...\n",
      "Epoch: 276... AvgLast100Score: 10.88030...\n",
      "Epoch: 277... AvgLast100Score: 11.02590...\n",
      "Epoch: 278... AvgLast100Score: 11.14960...\n",
      "Epoch: 279... AvgLast100Score: 11.26410...\n",
      "Epoch: 280... AvgLast100Score: 11.42450...\n",
      "Epoch: 281... AvgLast100Score: 11.53560...\n",
      "Epoch: 282... AvgLast100Score: 11.63510...\n",
      "Epoch: 283... AvgLast100Score: 11.71710...\n",
      "Epoch: 284... AvgLast100Score: 11.75830...\n",
      "Epoch: 285... AvgLast100Score: 11.83420...\n",
      "Epoch: 286... AvgLast100Score: 11.92620...\n",
      "Epoch: 287... AvgLast100Score: 11.95890...\n",
      "Epoch: 288... AvgLast100Score: 12.05660...\n",
      "Epoch: 289... AvgLast100Score: 12.17180...\n",
      "Epoch: 290... AvgLast100Score: 12.23850...\n",
      "Epoch: 291... AvgLast100Score: 12.30000...\n",
      "Epoch: 292... AvgLast100Score: 12.40720...\n",
      "Epoch: 293... AvgLast100Score: 12.51930...\n",
      "Epoch: 294... AvgLast100Score: 12.55370...\n",
      "Epoch: 295... AvgLast100Score: 12.67640...\n",
      "Epoch: 296... AvgLast100Score: 12.72670...\n",
      "Epoch: 297... AvgLast100Score: 12.87570...\n",
      "Epoch: 298... AvgLast100Score: 12.96980...\n",
      "Epoch: 299... AvgLast100Score: 12.96180...\n",
      "Epoch: 300... AvgLast100Score: 13.03870...\n",
      "Epoch: 301... AvgLast100Score: 13.13700...\n",
      "Epoch: 302... AvgLast100Score: 13.25080...\n",
      "Epoch: 303... AvgLast100Score: 13.30370...\n",
      "Epoch: 304... AvgLast100Score: 13.35880...\n",
      "Epoch: 305... AvgLast100Score: 13.46770...\n",
      "Epoch: 306... AvgLast100Score: 13.48740...\n",
      "Epoch: 307... AvgLast100Score: 13.50440...\n",
      "Epoch: 308... AvgLast100Score: 13.59330...\n",
      "Epoch: 309... AvgLast100Score: 13.64460...\n",
      "Epoch: 310... AvgLast100Score: 13.69790...\n",
      "Epoch: 311... AvgLast100Score: 13.79350...\n",
      "Epoch: 312... AvgLast100Score: 13.87310...\n",
      "Epoch: 313... AvgLast100Score: 13.92720...\n",
      "Epoch: 314... AvgLast100Score: 14.04260...\n",
      "Epoch: 315... AvgLast100Score: 14.12010...\n",
      "Epoch: 316... AvgLast100Score: 14.19420...\n",
      "Epoch: 317... AvgLast100Score: 14.16360...\n",
      "Epoch: 318... AvgLast100Score: 14.09900...\n",
      "Epoch: 319... AvgLast100Score: 14.04250...\n",
      "Epoch: 320... AvgLast100Score: 14.06380...\n",
      "Epoch: 321... AvgLast100Score: 14.05300...\n",
      "Epoch: 322... AvgLast100Score: 13.93000...\n",
      "Epoch: 323... AvgLast100Score: 14.04190...\n",
      "Epoch: 324... AvgLast100Score: 14.19830...\n",
      "Epoch: 325... AvgLast100Score: 14.28290...\n",
      "Epoch: 326... AvgLast100Score: 14.32110...\n",
      "Epoch: 327... AvgLast100Score: 14.38050...\n",
      "Epoch: 328... AvgLast100Score: 14.31920...\n",
      "Epoch: 329... AvgLast100Score: 14.34070...\n",
      "Epoch: 330... AvgLast100Score: 14.43300...\n",
      "Epoch: 331... AvgLast100Score: 14.48040...\n",
      "Epoch: 332... AvgLast100Score: 14.54930...\n",
      "Epoch: 333... AvgLast100Score: 14.75040...\n",
      "Epoch: 334... AvgLast100Score: 14.87620...\n",
      "Epoch: 335... AvgLast100Score: 14.96820...\n",
      "Epoch: 336... AvgLast100Score: 15.00240...\n",
      "Epoch: 337... AvgLast100Score: 15.12480...\n",
      "Epoch: 338... AvgLast100Score: 15.17020...\n",
      "Epoch: 339... AvgLast100Score: 15.26620...\n",
      "Epoch: 340... AvgLast100Score: 15.30930...\n",
      "Epoch: 341... AvgLast100Score: 15.35790...\n",
      "Epoch: 342... AvgLast100Score: 15.37260...\n",
      "Epoch: 343... AvgLast100Score: 15.51200...\n",
      "Epoch: 344... AvgLast100Score: 15.56800...\n",
      "Epoch: 345... AvgLast100Score: 15.65460...\n",
      "Epoch: 346... AvgLast100Score: 15.77030...\n",
      "Epoch: 347... AvgLast100Score: 15.90170...\n",
      "Epoch: 348... AvgLast100Score: 15.99720...\n",
      "Epoch: 349... AvgLast100Score: 16.13820...\n",
      "Epoch: 350... AvgLast100Score: 16.20280...\n",
      "Epoch: 351... AvgLast100Score: 16.33440...\n",
      "Epoch: 352... AvgLast100Score: 16.38370...\n",
      "Epoch: 353... AvgLast100Score: 16.51230...\n",
      "Epoch: 354... AvgLast100Score: 16.61210...\n",
      "Epoch: 355... AvgLast100Score: 16.73790...\n",
      "Epoch: 356... AvgLast100Score: 16.81060...\n",
      "Epoch: 357... AvgLast100Score: 16.94900...\n",
      "Epoch: 358... AvgLast100Score: 17.03160...\n",
      "Epoch: 359... AvgLast100Score: 17.12450...\n",
      "Epoch: 360... AvgLast100Score: 17.27780...\n",
      "Epoch: 361... AvgLast100Score: 17.42120...\n",
      "Epoch: 362... AvgLast100Score: 17.56000...\n",
      "Epoch: 363... AvgLast100Score: 17.64910...\n",
      "Epoch: 364... AvgLast100Score: 17.70170...\n",
      "Epoch: 365... AvgLast100Score: 17.81570...\n",
      "Epoch: 366... AvgLast100Score: 17.87710...\n",
      "Epoch: 367... AvgLast100Score: 17.90080...\n",
      "Epoch: 368... AvgLast100Score: 17.93280...\n",
      "Epoch: 369... AvgLast100Score: 17.99110...\n",
      "Epoch: 370... AvgLast100Score: 18.10360...\n",
      "Epoch: 371... AvgLast100Score: 18.29530...\n",
      "Epoch: 372... AvgLast100Score: 18.37720...\n",
      "Epoch: 373... AvgLast100Score: 18.47530...\n",
      "Epoch: 374... AvgLast100Score: 18.49080...\n",
      "Epoch: 375... AvgLast100Score: 18.64850...\n",
      "Epoch: 376... AvgLast100Score: 18.70480...\n",
      "Epoch: 377... AvgLast100Score: 18.77820...\n",
      "Epoch: 378... AvgLast100Score: 19.00390...\n",
      "Epoch: 379... AvgLast100Score: 19.10530...\n",
      "Epoch: 380... AvgLast100Score: 19.19360...\n",
      "Epoch: 381... AvgLast100Score: 19.17600...\n",
      "Epoch: 382... AvgLast100Score: 19.30680...\n",
      "Epoch: 383... AvgLast100Score: 19.39620...\n",
      "Epoch: 384... AvgLast100Score: 19.50370...\n",
      "Epoch: 385... AvgLast100Score: 19.69120...\n",
      "Epoch: 386... AvgLast100Score: 19.79240...\n",
      "Epoch: 387... AvgLast100Score: 19.96830...\n",
      "Epoch: 388... AvgLast100Score: 20.08100...\n",
      "Epoch: 389... AvgLast100Score: 20.17620...\n",
      "Epoch: 390... AvgLast100Score: 20.28890...\n",
      "Epoch: 391... AvgLast100Score: 20.40580...\n",
      "Epoch: 392... AvgLast100Score: 20.37430...\n",
      "Epoch: 393... AvgLast100Score: 20.46850...\n",
      "Epoch: 394... AvgLast100Score: 20.59470...\n",
      "Epoch: 395... AvgLast100Score: 20.67080...\n",
      "Epoch: 396... AvgLast100Score: 20.74740...\n",
      "Epoch: 397... AvgLast100Score: 20.83160...\n",
      "Epoch: 398... AvgLast100Score: 20.91020...\n",
      "Epoch: 399... AvgLast100Score: 21.06820...\n",
      "Epoch: 400... AvgLast100Score: 21.21020...\n",
      "Epoch: 401... AvgLast100Score: 21.31270...\n",
      "Epoch: 402... AvgLast100Score: 21.35550...\n",
      "Epoch: 403... AvgLast100Score: 21.59220...\n",
      "Epoch: 404... AvgLast100Score: 21.80440...\n",
      "Epoch: 405... AvgLast100Score: 21.88910...\n",
      "Epoch: 406... AvgLast100Score: 21.85480...\n",
      "Epoch: 407... AvgLast100Score: 22.06820...\n",
      "Epoch: 408... AvgLast100Score: 22.17760...\n",
      "Epoch: 409... AvgLast100Score: 22.37180...\n",
      "Epoch: 410... AvgLast100Score: 22.37280...\n",
      "Epoch: 411... AvgLast100Score: 22.40220...\n",
      "Epoch: 412... AvgLast100Score: 22.43580...\n",
      "Epoch: 413... AvgLast100Score: 22.56260...\n",
      "Epoch: 414... AvgLast100Score: 22.65700...\n",
      "Epoch: 415... AvgLast100Score: 22.80650...\n",
      "Epoch: 416... AvgLast100Score: 22.96360...\n",
      "Epoch: 417... AvgLast100Score: 23.14640...\n",
      "Epoch: 418... AvgLast100Score: 23.39280...\n",
      "Epoch: 419... AvgLast100Score: 23.56680...\n",
      "Epoch: 420... AvgLast100Score: 23.76290...\n",
      "Epoch: 421... AvgLast100Score: 23.91460...\n",
      "Epoch: 422... AvgLast100Score: 24.05070...\n",
      "Epoch: 423... AvgLast100Score: 24.01610...\n",
      "Epoch: 424... AvgLast100Score: 24.00650...\n",
      "Epoch: 425... AvgLast100Score: 24.03420...\n",
      "Epoch: 426... AvgLast100Score: 24.10010...\n",
      "Epoch: 427... AvgLast100Score: 24.23310...\n",
      "Epoch: 428... AvgLast100Score: 24.40710...\n",
      "Epoch: 429... AvgLast100Score: 24.43960...\n",
      "Epoch: 430... AvgLast100Score: 24.47450...\n",
      "Epoch: 431... AvgLast100Score: 24.54940...\n",
      "Epoch: 432... AvgLast100Score: 24.71160...\n",
      "Epoch: 433... AvgLast100Score: 24.67630...\n",
      "Epoch: 434... AvgLast100Score: 24.69750...\n",
      "Epoch: 435... AvgLast100Score: 24.85030...\n",
      "Epoch: 436... AvgLast100Score: 24.98240...\n",
      "Epoch: 437... AvgLast100Score: 25.05180...\n",
      "Epoch: 438... AvgLast100Score: 25.22240...\n",
      "Epoch: 439... AvgLast100Score: 25.28580...\n",
      "Epoch: 440... AvgLast100Score: 25.23550...\n",
      "Epoch: 441... AvgLast100Score: 25.36630...\n",
      "Epoch: 442... AvgLast100Score: 25.40700...\n",
      "Epoch: 443... AvgLast100Score: 25.37950...\n",
      "Epoch: 444... AvgLast100Score: 25.45700...\n",
      "Epoch: 445... AvgLast100Score: 25.57970...\n",
      "Epoch: 446... AvgLast100Score: 25.66860...\n",
      "Epoch: 447... AvgLast100Score: 25.71260...\n",
      "Epoch: 448... AvgLast100Score: 25.75700...\n",
      "Epoch: 449... AvgLast100Score: 25.71240...\n",
      "Epoch: 450... AvgLast100Score: 25.81860...\n",
      "Epoch: 451... AvgLast100Score: 25.86110...\n",
      "Epoch: 452... AvgLast100Score: 26.02040...\n",
      "Epoch: 453... AvgLast100Score: 26.02840...\n",
      "Epoch: 454... AvgLast100Score: 26.06140...\n",
      "Epoch: 455... AvgLast100Score: 26.16580...\n",
      "Epoch: 456... AvgLast100Score: 26.25130...\n",
      "Epoch: 457... AvgLast100Score: 26.32390...\n",
      "Epoch: 458... AvgLast100Score: 26.41210...\n",
      "Epoch: 459... AvgLast100Score: 26.52460...\n",
      "Epoch: 460... AvgLast100Score: 26.66020...\n",
      "Epoch: 461... AvgLast100Score: 26.70490...\n",
      "Epoch: 462... AvgLast100Score: 26.79400...\n",
      "Epoch: 463... AvgLast100Score: 26.94980...\n",
      "Epoch: 464... AvgLast100Score: 27.10500...\n",
      "Epoch: 465... AvgLast100Score: 27.21650...\n",
      "Epoch: 466... AvgLast100Score: 27.40090...\n",
      "Epoch: 467... AvgLast100Score: 27.56510...\n",
      "Epoch: 468... AvgLast100Score: 27.69790...\n",
      "Epoch: 469... AvgLast100Score: 27.88300...\n",
      "Epoch: 470... AvgLast100Score: 28.00100...\n",
      "Epoch: 471... AvgLast100Score: 28.03040...\n",
      "Epoch: 472... AvgLast100Score: 28.16050...\n",
      "Epoch: 473... AvgLast100Score: 28.20100...\n",
      "Epoch: 474... AvgLast100Score: 28.23580...\n",
      "Epoch: 475... AvgLast100Score: 28.24830...\n",
      "Epoch: 476... AvgLast100Score: 28.35630...\n",
      "Epoch: 477... AvgLast100Score: 28.43860...\n",
      "Epoch: 478... AvgLast100Score: 28.39790...\n",
      "Epoch: 479... AvgLast100Score: 28.49140...\n",
      "Epoch: 480... AvgLast100Score: 28.53150...\n",
      "Epoch: 481... AvgLast100Score: 28.76730...\n",
      "Epoch: 482... AvgLast100Score: 28.76670...\n",
      "Epoch: 483... AvgLast100Score: 28.89340...\n",
      "Epoch: 484... AvgLast100Score: 28.90550...\n",
      "Epoch: 485... AvgLast100Score: 28.91700...\n",
      "Epoch: 486... AvgLast100Score: 28.98660...\n",
      "Epoch: 487... AvgLast100Score: 28.98330...\n",
      "Epoch: 488... AvgLast100Score: 29.06710...\n",
      "Epoch: 489... AvgLast100Score: 29.17320...\n",
      "Epoch: 490... AvgLast100Score: 29.20170...\n",
      "Epoch: 491... AvgLast100Score: 29.15860...\n",
      "Epoch: 492... AvgLast100Score: 29.31600...\n",
      "Epoch: 493... AvgLast100Score: 29.31470...\n",
      "Epoch: 494... AvgLast100Score: 29.38770...\n",
      "Epoch: 495... AvgLast100Score: 29.49110...\n",
      "Epoch: 496... AvgLast100Score: 29.59210...\n",
      "Epoch: 497... AvgLast100Score: 29.62610...\n",
      "Epoch: 498... AvgLast100Score: 29.71860...\n",
      "Epoch: 499... AvgLast100Score: 29.82810...\n",
      "Epoch: 500... AvgLast100Score: 29.76130...\n",
      "Epoch: 501... AvgLast100Score: 29.63110...\n",
      "Epoch: 502... AvgLast100Score: 29.63450...\n",
      "Epoch: 503... AvgLast100Score: 29.62180...\n",
      "Epoch: 504... AvgLast100Score: 29.64310...\n",
      "Epoch: 505... AvgLast100Score: 29.66260...\n",
      "Epoch: 506... AvgLast100Score: 29.84820...\n",
      "Epoch: 507... AvgLast100Score: 29.92980...\n",
      "Epoch: 508... AvgLast100Score: 30.07930...\n",
      "\n",
      "Training Finished at episode 508 !!!\n",
      " AvgLast100Score: 30.07930...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f26c4772b38>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for episode in range(len(score_history), len(score_history)+3000):\n",
    "    isdone = False\n",
    "    score = 0\n",
    "    state0 = env.reset(train_mode=True)[brain_name].vector_observations[0]\n",
    "    episode_step = 0\n",
    "    while not isdone:\n",
    "        actionset0 = agent.choose_action(state0)\n",
    "        env_response = env.step(actionset0)[brain_name]\n",
    "        state1, reward1, isdone = env_response.vector_observations[0], env_response.rewards[0], env_response.local_done[0]\n",
    "        \n",
    "        if episode_step % 3 == 0:\n",
    "            agent.remark(state0, actionset0, reward1, state1, isdone)\n",
    "            agent.learn()\n",
    "        \n",
    "        score += reward1\n",
    "        state0 = state1\n",
    "        episode_step += 1\n",
    "    \n",
    "    score_history.append(score)\n",
    "    \n",
    "    if (episode+1) % 1 == 0:\n",
    "        print('Epoch: {}... AvgLast{}Score: {:.5f}...'.format( \\\n",
    "            episode+1, \n",
    "            100,\n",
    "            np.mean(score_history[-100:])\n",
    "        ))\n",
    "    \n",
    "    if np.mean(score_history[-100:]) > 30.:\n",
    "        break\n",
    "                      \n",
    "print('\\nTraining Finished at episode {} !!!\\n AvgLast100Score: {:.5f}...'.format(episode+1, np.mean(score_history[-100:])))  \n",
    "plot_episode_scores(score_history, 30.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "agent.critic.save_checkpoint()\n",
    "agent.actor.save_checkpoint()\n",
    "agent.critic_target.save_checkpoint()\n",
    "agent.actor_target.save_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(agent.critic.state_dict(), 'cl1.state')\n",
    "torch.save(agent.critic_target.state_dict(), 'ct1.state')\n",
    "torch.save(agent.actor.state_dict(), 'al1.state')\n",
    "torch.save(agent.actor_target.state_dict(), 'at1.state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('scores1.npy', score_history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
